{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Копия Фильм_часть3_генерация-фильма-по-кадрам","provenance":[{"file_id":"1Z2n4qtcArGDvn3oOidA2RhWapODYgE-1","timestamp":1630832918372},{"file_id":"https://github.com/borisdayma/dalle-mini/blob/main/dev/inference/inference_pipeline.ipynb","timestamp":1629375782664}],"collapsed_sections":["fmdAt9ASiJSg","phQ9bhjRkgAZ","kUF-DjskUIWF","sux8rAgpUU9V","lTIXzGYriYM7","M_nU-SeYimk0","_8qHzYgtiyOG","PDX73YQWgZ6Y","-AwAZxYHjNqI","PBmOVndkNRQo","SWLRt-7VNlwY","TEeP_3wMS6i3"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"dS8LbaonYm3a"},"source":["#Генерация картинок"]},{"cell_type":"markdown","metadata":{"id":"fmdAt9ASiJSg"},"source":["##Установка"]},{"cell_type":"code","metadata":{"id":"uzjAM2GBYpZX"},"source":["!pip install -q transformers flax\n","!pip install -q git+https://github.com/patil-suraj/vqgan-jax.git  # VQGAN model in JAX\n","!git clone https://github.com/borisdayma/dalle-mini  # Model files\n","%cd dalle-mini/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AwGeNXXUZUvp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634404932421,"user_tz":-180,"elapsed":21968,"user":{"displayName":"Дарья Курганская","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10001247416734268166"}},"outputId":"ce6d0cb9-1d46-4fbf-a3a0-6fa0f90127c1"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"phQ9bhjRkgAZ"},"source":["##Модели"]},{"cell_type":"code","metadata":{"id":"yyT4tk5EbsdO"},"source":["from dalle_mini.model import CustomFlaxBartForConditionalGeneration\n","from transformers import BartTokenizer\n","import jax\n","import random\n","from tqdm.notebook import tqdm, trange"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pHv8hKFpcF7R"},"source":["#dalle mini\n","DALLE_REPO = 'flax-community/dalle-mini'\n","DALLE_COMMIT_ID = '4d34126d0df8bc4a692ae933e3b902a1fa8b6114'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k82AaQlGcq0V"},"source":["# set up tokenizer and model\n","tokenizer = BartTokenizer.from_pretrained(DALLE_REPO, revision=DALLE_COMMIT_ID)\n","model = CustomFlaxBartForConditionalGeneration.from_pretrained(DALLE_REPO, revision=DALLE_COMMIT_ID)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x8TcTLaBO5Jm"},"source":["from vqgan_jax.modeling_flax_vqgan import VQModel\n","import numpy as np\n","from PIL import Image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7E33V_lXO5tv"},"source":["#vqgan\n","VQGAN_REPO = 'flax-community/vqgan_f16_16384'\n","VQGAN_COMMIT_ID = '90cc46addd2dd8f5be21586a9a23e1b95aa506a9'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UuOE1sFBPC9Q"},"source":["vqgan = VQModel.from_pretrained(VQGAN_REPO, revision=VQGAN_COMMIT_ID)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d18EmCE9PqVP"},"source":["#clip\n","from transformers import CLIPProcessor, FlaxCLIPModel"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lNfnYVj3PqoE"},"source":["clip = FlaxCLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n","processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MvsaEy2nSECy"},"source":["import imageio"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TjUeS5E3PDPx"},"source":["%cd .."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kUF-DjskUIWF"},"source":["## Текст"]},{"cell_type":"code","metadata":{"id":"wROEG87yuZsf"},"source":["data=[{'start': 9.1718820861678,\n","  'text': 'One sunny day, the four wives of the old British consul, the vicar, and a young couple head to the seaside country of Oaxham to attend the wedding of a young man'},\n"," {'start': 12.469115646258503,\n","  'text': ' The three old ladies are all of married social standing'}]\n"," #!!!вставить таймкод истории!!!"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m4qYPk2d2sGc"},"source":["len(data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sux8rAgpUU9V"},"source":["##Генерация"]},{"cell_type":"code","metadata":{"id":"W8pQzeO2Ua8N"},"source":["n_predictions = 10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RdcsZHgNiRVx"},"source":["path = '/content/drive/MyDrive/aiijc/newFilm/pix1' #@param {type:'string'}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ENCNOWPfOOjy"},"source":["\n","for j in range(len(data)):\n","  prompt = data[j]['text']\n","  tokenized_prompt = tokenizer(prompt, return_tensors='jax', padding='max_length', truncation=True, max_length=128)\n","\n","  scores = 0\n","  best = 0\n","  final_img = 0\n","\n","  # create random keys\n","  seed = random.randint(0, 2**32-1)\n","  key = jax.random.PRNGKey(seed)\n","  subkeys = jax.random.split(key, num=n_predictions)\n","  \n","  encoded_images = [model.generate(**tokenized_prompt, do_sample=True, num_beams=1, prng_key=subkey) for subkey in tqdm(subkeys)]\n","  encoded_images = [img.sequences[..., 1:] for img in encoded_images]\n","  decoded_images = [vqgan.decode_code(encoded_image) for encoded_image in tqdm(encoded_images)]\n","  clipped_images = [img.squeeze().clip(0., 1.) for img in decoded_images]\n","  images = [Image.fromarray(np.asarray(img * 255, dtype=np.uint8)) for img in clipped_images]\n","  # evaluate scores\n","  inputs = processor(text=prompt, images=images, return_tensors='np')\n","  logits = clip(**inputs).logits_per_image\n","  scores = jax.nn.softmax(logits, axis=0).squeeze()  # normalize and sum all scores to 1\n","  print(f'Prompt: {prompt}\\n')\n","  for i in scores.argsort()[::-1]:\n","    if scores[i]>best:\n","      best = scores[i]\n","      final_img = i\n","  print(f'Score: {scores[final_img]}')\n","  display(images[final_img])\n","  print()\n","  \n","  filename = f\"{path}/{j:03}.png\"\n","  imageio.imwrite(filename, np.array(images[final_img]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Y2qz7t9SeIX"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lTIXzGYriYM7"},"source":["#Увеличение размера"]},{"cell_type":"markdown","metadata":{"id":"M_nU-SeYimk0"},"source":["## Инициализация"]},{"cell_type":"code","metadata":{"id":"Bz4BqJBkidD1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633438396666,"user_tz":-180,"elapsed":17788,"user":{"displayName":"Дарья Курганская","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00136910481207940866"}},"outputId":"cdde681d-3828-4249-b25e-426dbe1d772c"},"source":["#@title Установка необходимых пакетов\n","!pip install torch\n","!pip install torchvision\n","!pip install numpy\n","!pip install pillow\n","\n","!gdown https://drive.google.com/uc?id=1Or9gVJKghtBwiVMWaNnYRj3TPAfkvSNa\n","!unzip sr_weights.zip"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.10.0+cu102)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n","Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.9.0+cu102)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchvision) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n","Downloading...\n","From: https://drive.google.com/uc?id=1Or9gVJKghtBwiVMWaNnYRj3TPAfkvSNa\n","To: /content/sr_weights.zip\n","108MB [00:00, 112MB/s] \n","Archive:  sr_weights.zip\n","  inflating: netG_20blocks_comprandom_dsV4_4x_V3bicubic.pth  \n","  inflating: RRDBNet_PSNR_20blocks_comprandom_dsV4_4x_V3bicubic.pth  \n"]}]},{"cell_type":"code","metadata":{"id":"ldCnqc0nivDN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633438411622,"user_tz":-180,"elapsed":14964,"user":{"displayName":"Дарья Курганская","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00136910481207940866"}},"outputId":"2a1f120d-38c3-43ff-dd17-09e716edd534"},"source":["#@title Загрузка предобученной модели\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.transforms.functional as FT\n","import math\n","import numpy as np\n","from PIL import Image\n","from collections import OrderedDict\n","\n","class Generator(nn.Module):\n","    def __init__(self, num_rrdb_blocks=16, tanh_output=True, upscale_factor=4):\n","        super(Generator, self).__init__()\n","        \n","        self.num_upsample_blocks = int(math.log2(upscale_factor))\n","        \n","        # First layer\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n","\n","        # 16/23 ResidualInResidualDenseBlock layer\n","        rrdb_blocks = []\n","        for _ in range(num_rrdb_blocks):\n","            rrdb_blocks += [ResidualInResidualDenseBlock(64, 32, 0.2)]\n","        self.Trunk_RRDB = nn.Sequential(*rrdb_blocks)\n","\n","        # Second conv layer post residual blocks\n","        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n","\n","        # Upsampling layers\n","        #self.up1 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n","        #self.up2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n","        upsample_blocks = []\n","        for _ in range(self.num_upsample_blocks):\n","            upsample_blocks += [InterpolateUpsampleBlock(64,64,kernel_size=3, stride=1, padding=1)]\n","        self.upblocks = nn.Sequential(*upsample_blocks)\n","        \n","        # Next layer after upper sampling\n","        self.conv3 = nn.Sequential(\n","            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n","            nn.LeakyReLU(negative_slope=0.2, inplace=True)\n","        )\n","        \n","        # Final output layer\n","        if not tanh_output:\n","\n","            self.conv4 = nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=1)\n","        else:\n","            self.conv4 = nn.Sequential(\n","                nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=1),\n","                nn.Tanh()\n","            )\n","\n","    def forward(self, input: torch.Tensor) -> torch.Tensor:\n","        out1 = self.conv1(input)\n","        trunk = self.Trunk_RRDB(out1)\n","        out2 = self.conv2(trunk)\n","        out = torch.add(out1, out2)\n","        out = self.upblocks(out)\n","        out = self.conv3(out)\n","        out = self.conv4(out)\n","\n","        return out\n","\n","\n","class InterpolateUpsampleBlock(nn.Module):\n","    \n","    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int, padding: int):\n","        super(InterpolateUpsampleBlock, self).__init__()\n","        \n","        self.up = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, \n","                            stride=stride, padding=padding)\n","   \n","    def forward(self, input: torch.Tensor) -> torch.Tensor:\n","        return F.leaky_relu(self.up(F.interpolate(input, scale_factor=2, mode=\"bicubic\", align_corners=True)), 0.2, True)\n","    \n","    \n","class ResidualDenseBlock(nn.Module):\n","\n","    def __init__(self, channels: int = 64, growth_channels: int = 32, scale_ratio: float = 0.2):\n","\n","        super(ResidualDenseBlock, self).__init__()\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(channels + 0 * growth_channels, growth_channels, kernel_size=3, stride=1, padding=1),\n","            nn.LeakyReLU(negative_slope=0.2, inplace=True)\n","        )\n","        self.conv2 = nn.Sequential(\n","            nn.Conv2d(channels + 1 * growth_channels, growth_channels, kernel_size=3, stride=1, padding=1),\n","            nn.LeakyReLU(negative_slope=0.2, inplace=True)\n","        )\n","        self.conv3 = nn.Sequential(\n","            nn.Conv2d(channels + 2 * growth_channels, growth_channels, kernel_size=3, stride=1, padding=1),\n","            nn.LeakyReLU(negative_slope=0.2, inplace=True)\n","        )\n","        self.conv4 = nn.Sequential(\n","            nn.Conv2d(channels + 3 * growth_channels, growth_channels, kernel_size=3, stride=1, padding=1),\n","            nn.LeakyReLU(negative_slope=0.2, inplace=True)\n","        )\n","        self.conv5 = nn.Conv2d(channels + 4 * growth_channels, channels, kernel_size=3, stride=1, padding=1)\n","\n","        self.scale_ratio = scale_ratio\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight)\n","                m.weight.data *= 0.1\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.Linear):\n","                nn.init.kaiming_normal_(m.weight)\n","                m.weight.data *= 0.1\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias.data, 0.0)\n","\n","    def forward(self, input: torch.Tensor) -> torch.Tensor:\n","        conv1 = self.conv1(input)\n","        conv2 = self.conv2(torch.cat((input, conv1), 1))\n","        conv3 = self.conv3(torch.cat((input, conv1, conv2), 1))\n","        conv4 = self.conv4(torch.cat((input, conv1, conv2, conv3), 1))\n","        conv5 = self.conv5(torch.cat((input, conv1, conv2, conv3, conv4), 1))\n","\n","        return conv5.mul(self.scale_ratio) + input\n","\n","\n","class ResidualInResidualDenseBlock(nn.Module):\n","\n","    def __init__(self, channels: int = 64, growth_channels: int = 32, scale_ratio: float = 0.2):\n","\n","        super(ResidualInResidualDenseBlock, self).__init__()\n","        self.RDB1 = ResidualDenseBlock(channels, growth_channels, scale_ratio)\n","        self.RDB2 = ResidualDenseBlock(channels, growth_channels, scale_ratio)\n","        self.RDB3 = ResidualDenseBlock(channels, growth_channels, scale_ratio)\n","\n","        self.scale_ratio = scale_ratio\n","\n","    def forward(self, input: torch.Tensor) -> torch.Tensor:\n","        out = self.RDB1(input)\n","        out = self.RDB2(out)\n","        out = self.RDB3(out)\n","\n","        return out.mul(self.scale_ratio) + input\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Some constants\n","rgb_weights = torch.FloatTensor([65.481, 128.553, 24.966]).to(device)\n","imagenet_mean = torch.FloatTensor([0.485, 0.456, 0.406]).unsqueeze(1).unsqueeze(2)\n","imagenet_std = torch.FloatTensor([0.229, 0.224, 0.225]).unsqueeze(1).unsqueeze(2)\n","imagenet_mean_cuda = torch.FloatTensor([0.485, 0.456, 0.406]).to(device).unsqueeze(0).unsqueeze(2).unsqueeze(3)\n","imagenet_std_cuda = torch.FloatTensor([0.229, 0.224, 0.225]).to(device).unsqueeze(0).unsqueeze(2).unsqueeze(3)\n","\n","\n","def convert_image(img, source, target):\n","    assert source in {'pil', '[0, 1]', '[-1, 1]'}, \"Cannot convert from source format %s!\" % source\n","    assert target in {'pil', '[0, 255]', '[0, 1]', '[-1, 1]', 'imagenet-norm',\n","                      'y-channel'}, \"Cannot convert to target format %s!\" % target\n","\n","    # Convert from source to [0, 1]\n","    if source == 'pil':\n","        img = FT.to_tensor(img)\n","\n","    elif source == '[0, 1]':\n","        pass  # already in [0, 1]\n","\n","    elif source == '[-1, 1]':\n","        img = (img + 1.) / 2.\n","\n","    # Convert from [0, 1] to target\n","    if target == 'pil':\n","        img = FT.to_pil_image(img)\n","\n","    elif target == '[0, 255]':\n","        img = 255. * img\n","\n","    elif target == '[0, 1]':\n","        pass  # already in [0, 1]\n","\n","    elif target == '[-1, 1]':\n","        img = 2. * img - 1.\n","\n","    elif target == 'imagenet-norm':\n","        if img.ndimension() == 3:\n","            img = (img - imagenet_mean) / imagenet_std\n","        elif img.ndimension() == 4:\n","            img = (img - imagenet_mean_cuda) / imagenet_std_cuda\n","\n","    elif target == 'y-channel':\n","        img = torch.matmul(255. * img.permute(0, 2, 3, 1)[:, 4:-4, 4:-4, :], rgb_weights) / 255. + 16.\n","\n","    return img\n","\n","\n","def process_array(image_array, expand=True):\n","\n","    image_batch = image_array / 255.0\n","    if expand:\n","        image_batch = np.expand_dims(image_batch, axis=0)\n","    return image_batch\n","\n","\n","def process_output(output_tensor):\n","\n","    sr_img = output_tensor.clip(0, 1) * 255\n","    sr_img = np.uint8(sr_img)\n","    return sr_img\n","\n","\n","def pad_patch(image_patch, padding_size, channel_last=True):\n","\n","    if channel_last:\n","        return np.pad(\n","            image_patch,\n","            ((padding_size, padding_size), (padding_size, padding_size), (0, 0)),\n","            'edge',\n","        )\n","    else:\n","        return np.pad(\n","            image_patch,\n","            ((0, 0), (padding_size, padding_size), (padding_size, padding_size)),\n","            'edge',\n","        )\n","\n","\n","def unpad_patches(image_patches, padding_size):\n","    return image_patches[:, padding_size:-padding_size, padding_size:-padding_size, :]\n","\n","\n","def split_image_into_overlapping_patches(image_array, patch_size, padding_size=2):\n","    \n","    xmax, ymax, _ = image_array.shape\n","    x_remainder = xmax % patch_size\n","    y_remainder = ymax % patch_size\n","    \n","    # modulo here is to avoid extending of patch_size instead of 0\n","    x_extend = (patch_size - x_remainder) % patch_size\n","    y_extend = (patch_size - y_remainder) % patch_size\n","    \n","    # make sure the image is divisible into regular patches\n","    extended_image = np.pad(image_array, ((0, x_extend), (0, y_extend), (0, 0)), 'edge')\n","    \n","    # add padding around the image to simplify computations\n","    padded_image = pad_patch(extended_image, padding_size, channel_last=True)\n","    \n","    xmax, ymax, _ = padded_image.shape\n","    patches = []\n","    \n","    x_lefts = range(padding_size, xmax - padding_size, patch_size)\n","    y_tops = range(padding_size, ymax - padding_size, patch_size)\n","    \n","    for x in x_lefts:\n","        for y in y_tops:\n","            x_left = x - padding_size\n","            y_top = y - padding_size\n","            x_right = x + patch_size + padding_size\n","            y_bottom = y + patch_size + padding_size\n","            patch = padded_image[x_left:x_right, y_top:y_bottom, :]\n","            patches.append(patch)\n","    \n","    return np.array(patches), padded_image.shape\n","\n","\n","def stich_together(patches, padded_image_shape, target_shape, padding_size=4):\n","\n","    xmax, ymax, _ = padded_image_shape\n","    patches = unpad_patches(patches, padding_size)\n","    patch_size = patches.shape[1]\n","    n_patches_per_row = ymax // patch_size\n","    \n","    complete_image = np.zeros((xmax, ymax, 3))\n","    \n","    row = -1\n","    col = 0\n","    for i in range(len(patches)):\n","        if i % n_patches_per_row == 0:\n","            row += 1\n","            col = 0\n","        complete_image[\n","        row * patch_size: (row + 1) * patch_size, col * patch_size: (col + 1) * patch_size,:\n","        ] = patches[i]\n","        col += 1\n","    return complete_image[0: target_shape[0], 0: target_shape[1], :]\n","\n","\n","def load_inter_weights(psnr_path, gan_path, alpha=0.75):\n","    psnr_w = torch.load(psnr_path)\n","    gan_w = torch.load(gan_path)\n","\n","    inter_w = OrderedDict()\n","\n","    for k, w_psnr in psnr_w.items():\n","        w_gan = gan_w[k]\n","        inter_w[k] = (1 - alpha) * w_psnr + alpha * w_gan\n","\n","    return inter_w\n","\n","\n","def predict_by_patches(model, lr_img, batch_size=4, patches_size=192,\n","                       padding=15, scale=4):\n","    lr_image = np.array(lr_img)\n","    patches, p_shape = split_image_into_overlapping_patches(lr_image, patch_size=patches_size, \n","                                                            padding_size=padding)\n","    img = torch.FloatTensor(patches/255).permute((0,3,1,2)).to(device)\n","    img = convert_image(img, source='[0, 1]', target='imagenet-norm')\n","\n","    with torch.no_grad():\n","        torch.cuda.empty_cache()\n","        res = model(img[0:batch_size]).detach().cpu()\n","        for i in range(batch_size, img.shape[0], batch_size):\n","            res = torch.cat((res, model(img[i:i+batch_size]).detach().cpu()), 0)\n","\n","    sr_image = convert_image(res, source='[-1, 1]', target='[0, 1]').permute((0,2,3,1))\n","    np_sr_image = np.array(sr_image.data)\n","\n","    padded_size_scaled = tuple(np.multiply(p_shape[0:2], scale)) + (3,)\n","    scaled_image_shape = tuple(np.multiply(lr_image.shape[0:2], scale)) + (3,)\n","    np_sr_image = stich_together(np_sr_image, padded_image_shape=padded_size_scaled,\n","                            target_shape=scaled_image_shape, padding_size=padding * scale)\n","    sr_img = Image.fromarray((np_sr_image*255).astype(np.uint8))\n","    return sr_img\n","\n","checkpoint_gan = 'netG_20blocks_comprandom_dsV4_4x_V3bicubic.pth'\n","checkpoint_psnr = 'RRDBNet_PSNR_20blocks_comprandom_dsV4_4x_V3bicubic.pth'\n","model = Generator(num_rrdb_blocks=20)\n","inter_w = load_inter_weights(checkpoint_psnr, checkpoint_gan, alpha=0.95)\n","model.load_state_dict(inter_w)\n","model.cuda()\n","print('Модель готова к работе')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Модель готова к работе\n"]}]},{"cell_type":"code","metadata":{"id":"lucaHH7uixU1"},"source":["from IPython.display import display\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_8qHzYgtiyOG"},"source":["##Первое увеличение моделью"]},{"cell_type":"code","metadata":{"id":"r7N6mrszOtVO"},"source":["#@title Размер картинки (рекомендованно 1024*1024)\n","pix1024=True #@param {type:'boolean'}\n","pix4096=False #@param {type:'boolean'}\n","\n","times=0\n","if pix1024:\n","  times=1\n","elif pix4096:\n","  times=2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mG142Km6i73x"},"source":["#@title Генерация изображения\n","#@markdown На изображениях с размером более 1024 пикселей модель может работать очень долго!\n","\n","for j in range(len(data)):\n","   try:\n","    lr_img = Image.open(f'{path}/{j:03}.png').convert('RGB')\n","   except FileNotFoundError:\n","    continue\n","\n","   for t in range(times):\n","    result = predict_by_patches(model, lr_img)\n","    lr_img = result\n","\n","   result.save(f'{path}/{j:03}.png')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PDX73YQWgZ6Y"},"source":["##Второе увеличение интерпиляцией"]},{"cell_type":"code","metadata":{"id":"WoII47yOi3EN"},"source":["import cv2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YHZL0CTLiMAw"},"source":["#@title Размер картинки (рекомендованно 4096*4096)\n","pix2048=False #@param {type:'boolean'}\n","pix4096=True #@param {type:'boolean'}\n","pix8192=False #@param {type:'boolean'}\n","\n","if pix4096:\n","  pix = 4096\n","elif pix8192:\n","  pix = 8192\n","elif pix2048:\n","  pix = 2048"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OYh-fOhyiMR4"},"source":["for file in os.listdir(path):\n","  img=cv2.imread(f'{path}/{file}')\n","  resized = cv2.resize(img, (pix,pix), interpolation=cv2.INTER_NEAREST)\n","  cv2.imwrite(f'{path}/{file}', resized)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eYUr5JT_jSRu"},"source":["#мы используем два типа увеличения картинки для ускорения процесса и увеличения качества картинки"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-AwAZxYHjNqI"},"source":["#Сбор видео"]},{"cell_type":"markdown","metadata":{"id":"PBmOVndkNRQo"},"source":["##Инициализация"]},{"cell_type":"code","metadata":{"id":"WkJDNSnQNQmG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634404847382,"user_tz":-180,"elapsed":7440,"user":{"displayName":"Дарья Курганская","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10001247416734268166"}},"outputId":"e1073f44-0822-4f62-b737-414011ec8cf5"},"source":["!pip install opencv-python\n","!pip install natsort"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n","Requirement already satisfied: natsort in /usr/local/lib/python3.7/dist-packages (5.5.0)\n"]}]},{"cell_type":"code","metadata":{"id":"riTE1NiINXLB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634405085359,"user_tz":-180,"elapsed":292,"user":{"displayName":"Дарья Курганская","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10001247416734268166"}},"outputId":"c6f128d5-a3ed-41a1-ea8c-a9f785f7ded6"},"source":["import os\n","import cv2 \n","from PIL import Image \n","import natsort\n","from google.colab.patches import cv2_imshow\n","from datetime import datetime\n","import shutil\n","\n","# Проверка текущего пути к каталогу\n","\n","# print(os.getcwd()) \n","\n","path_main = path # базовая папка, в которой будут сохранены все данные \n","os.chdir(path_main)\n","\n","try:\n","    os.mkdir('Sci_morph') # Создание папки и проверка её на наличие в директории\n","except OSError:\n","    pass\n","\n","try:\n","    os.mkdir('Sci_pictures') # Создание папки и проверка её на наличие в директории\n","except OSError:\n","    pass\n","\n","path_for_morph = f\"{path}/Sci_morph\" # Папка, которая содержит изображения для морфинга.\n","                                  # Из неё будут извлечены изображения для генерации видео-морфинга (Вручную добавить изображения)!!!\n","\n","path_for_video_series = f\"{path}/Sci_pictures\" # Папка, которая содержит изображения для видеорядов. Добавьте те же изображения, что и в 'path_for_morph'.\n","                                  # Из неё будут извлечены изображения для генерации видеоряда (Вручную добавить изображения)!!!\n","\n","name_output_video = 'my_concatenation_final_video' # Название выходного видео в формате .mp4\n","\n","os.chdir(path_for_morph)\n","#\n","path = os.getcwd()  \n","print(\"Текущая рабочая директория %s\" % path) # определяем текущий каталог и печатаем"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Текущая рабочая директория /content/drive/MyDrive/aiijc/newFilm/pix1/Sci_morph\n"]}]},{"cell_type":"code","metadata":{"id":"xMremUFrEsIy"},"source":["import cv2\n","for file in os.listdir(path):\n","   img = cv2.imread(f'{path}/{file}')\n","   cv2.imwrite(f'{path_for_morph}/{file}', img)\n","   cv2.imwrite(f'{path_for_video_series}/{file}', img)\n","#Не обращать внимания на ошибку вызванную тем, что в данной директории есть ещё папки"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SWLRt-7VNlwY"},"source":["##Видео"]},{"cell_type":"code","metadata":{"id":"xud-3__bNsl4"},"source":["from PIL import Image\n","import numpy as np\n","import os \n","from tqdm import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"htVChIO1NlOx"},"source":["mean_height = 0\n","\n","mean_width = 0\n","\n","num_of_images = len(os.listdir('.'))\n","\n","running = True # Запуск генерации видео\n","\n","# print (num_of_images)\n","\n","for file in os.listdir('.'):\n","    if os.path.isfile(file) and file.endswith(\".jpg\") or file.endswith(\".jpeg\") or file.endswith(\"png\"):\n","        im = Image.open(os.path.join(path, file))\n","\n","        width, height = im.size\n","\n","        mean_width += width\n","\n","        mean_height += height\n","\n","        # im.show () # раскомментируйте это для отображения изображения\n","\n","  \n","# Нахождение средней высоты и ширины всех изображений.\n","# Это необходимо, потому что требуется видеокадр\n","# устанавливается одинаковой шириной и высотой. В противном случае\n","# изображения не равные этой ширине высота не получится\n","# встроено в видео\n","\n","try:\n","    mean_width = int(mean_width / num_of_images)\n","    mean_height = int(mean_height / num_of_images)\n","except ZeroDivisionError:\n","    running = False\n","    print('Отсутствуют изображения! Проверьте их наличие.')\n","\n","  \n","# print (mean_height)\n","# print (mean_width)\n","\n","  \n","# Изменение размера изображений, чтобы дать\n","# их одинаковой ширины и высоты\n","list_img = natsort.natsorted(os.listdir('.'))\n","\n","\n","def delete_pictures(): # Функция удаления файлов, папок\n","    os.chdir(path_for_morph)\n","    folder = '.'\n","    for the_file in os.listdir(folder):\n","        file_path = os.path.join(folder, the_file)\n","        try:\n","            if file_path.endswith(\".jpg\") or file_path.endswith(\".jpeg\") or file_path.endswith(\"png\"):\n","                os.unlink(file_path)\n","            elif os.path.isdir(file_path): shutil.rmtree(file_path)\n","        except Exception as e:\n","            pass\n","            \n","\n","if running:\n","    for num, file in enumerate(list_img):\n","          if file.endswith(\".jpg\") or file.endswith(\".jpeg\") or file.endswith(\"png\"):\n","              try:\n","                  # открытие изображения с помощью PIL Image\n","\n","                  img = cv2.imread(f\"{path_for_morph}/{file}\")\n","\n","                  img2 = cv2.imread(f\"{path_for_morph}/{list_img[num + 1]}\")\n","\n","                  dis = 10.0 # iterations \n","                  piece = 1.0 / dis\n","\n","                  for i in range(int(dis)):\n","                      \n","                      dst = cv2.addWeighted(img, 1 - (piece * (i)), img2, piece * (i + 1), 0)\n","                      name_file = str(file.split('.')[0]) + '_' + str(i) + '.png'\n","                      print(name_file)\n","                      cv2.imwrite(name_file, dst)\n","                      print(name_file)\n","\n","                  os.remove(file)\n","              except Exception as e:\n","                pass\n","\n","    list_img = natsort.natsorted(os.listdir('.'))\n","\n","    for num, file in enumerate(list_img):\n","        if file.endswith(\".jpg\") or file.endswith(\".jpeg\") or file.endswith(\"png\"):\n","            # открытие изображения с помощью PIL Image\n","\n","            im = Image.open(os.path.join(path, file))\n","\n","            # im.size включает в себя высоту и ширину изображения\n","\n","            width, height = im.size   \n","\n","            # изменение размера\n","\n","            imResize = im.resize((mean_width, mean_height), Image.ANTIALIAS) \n","\n","            imResize.save( file, 'JPEG', quality = 95) # настройка качества\n","\n","            #print(im.filename.split('\\\\')[-1], \" is resized\") # печать каждого измененного имени изображения\n","\n","\n","    def generate_video(): # Функция создания видео\n","        image_folder = '.' # убедитесь, что используете вашу папку\n","\n","        os.chdir(path_for_morph)\n","\n","        images = [img for img in natsort.natsorted(os.listdir(image_folder))\n","\n","                  if img.endswith(\".jpg\") or\n","\n","                    img.endswith(\".jpeg\") or\n","\n","                    img.endswith(\"png\")]\n","\n","        # Изображения массива должны учитывать только\n","        # файлы изображений, игнорируя другие, если таковые имеются\n","\n","        frame = cv2.imread(os.path.join(image_folder, images[0]))\n","\n","        # настройка ширины рамки, высоты по ширине\n","        # ширина, высота первого изображения\n","\n","        height, width, layers = frame.shape  \n","\n","        speed_fps = 10.0 # Скорость отображения изображений(ВАЖНО!!!)\n","\n","        # Добавление изображений к видео по одному\n","        count = 1\n","        name_num = 0\n","\n","        for num, image in enumerate(images):\n","            if num == 0:\n","                video_name = f'video_output_{name_num}.mp4'\n","                video = cv2.VideoWriter(video_name, 0x7634706d, speed_fps, (width, height))\n","            if count <= 10:\n","                pass\n","            else:\n","                cv2.destroyAllWindows() # Распределение памяти, взятой для создания окна\n","                video.release()  # выпуск сгенерированного видео\n","                                # Видео будет храниться в этой же папке в формате .mp4\n","                name_num += 1\n","                count = 1\n","                video_name = f'video_output_{name_num}.mp4'\n","                video = cv2.VideoWriter(video_name, 0x7634706d, speed_fps, (width, height)) \n","\n","            video.write(cv2.imread(os.path.join(image_folder, image))) \n","            count += 1\n","\n","        delete_pictures()\n","\n","    generate_video() # Вызов функции generate_video\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ufbi1fvNNrHL"},"source":["!mkdir videos1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OB9M9sw4Nakw"},"source":["%cd videos1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DHLFvnDLJWrK"},"source":["data = [{'start': 4.4117913832199545,\n","  'text': 'One sunny day, a man named Charlie (Stephen Merchant) shows up at the beach'},\n"," {'start': 11.633197278911563,\n","  'text': ' He finds an old woman named Emily with a necklace in her locker Charlie is curious about the necklace and later, when Emily finds'},\n"," {'start': 18.297324263038547,\n","  'text': ' a piece of paper on the beach, he starts playing around and thinks Emily might have something to do with his name on the necklace'},\n"," {'start': 22.755555555555553,\n","  'text': ' While he is thinking of this, Charlie starts thinking that the necklace on the beach'},\n"," {'start': 27.353106575963714,\n","  'text': \" and he decides to find the woman from the old woman's locker and keep the necklace\"},\n"," {'start': 30.209160997732422,\n","  'text': ' Emily eventually agrees to give him the necklace, '},\n"," {'start': 33.11165532879818,\n","  'text': ' but on the way he sees someone wearing the necklace'},\n"," {'start': 35.665850340136046,\n","  'text': '^ I need a piece of paper. Write on it ^ '},\n"," {'start': 38.66122448979591,\n","  'text': 'He grabs a piece of paper to start writing on it'},\n"," {'start': 41.37795918367346,\n","  'text': \" The paper breaks and he sees Emily's name on it\"},\n"," {'start': 43.04979591836734, 'text': ' ^ I need a piece of paper ^ '},\n"," {'start': 46.27736961451246,\n","  'text': ' He starts to write more on the paper and then runs in'},\n"," {'start': 49.45850340136053,\n","  'text': ' to one of the girls who is also looking for the necklace'},\n"," {'start': 53.98639455782312,\n","  'text': ' They all realize that they have the same goal and decide to help him find the woman'},\n"," {'start': 58.28208616780044,\n","  'text': ' After they leave, they see the girl in the locker and decide to follow her '},\n"," {'start': 61.48643990929704,\n","  'text': ' Soon, they are attacked by some men and chased by a dog'},\n"," {'start': 66.15365079365078,\n","  'text': ' Later, the same girl who the old lady saw in the locker is attacked by a dog'},\n"," {'start': 68.61496598639455,\n","  'text': ' Charlie is confused about who is she '},\n"," {'start': 72.37659863945578,\n","  'text': ' He then runs up to the old woman and claims to know what happened'},\n"," {'start': 75.67383219954648,\n","  'text': ' She starts looking for the necklace she got from the old woman'},\n"," {'start': 78.64598639455782,\n","  'text': ' and then a police officer shows up at the beach'},\n"," {'start': 82.96489795918367,\n","  'text': ' The police officer tells Charlie that he was on the way home from work'},\n"," {'start': 86.40145124716554,\n","  'text': ' that day and that he found the necklace and the dog in the beach'},\n"," {'start': 90.23274376417234,\n","  'text': ' Charlie goes back to the old woman to get the necklace, but she '},\n"," {'start': 93.87827664399093,\n","  'text': ' throws Charlie out of the house and then tries to call the police'},\n"," {'start': 98.42938775510204,\n","  'text': ' Charlie hears her crying and tries to talk to her, but she is unable to speak'},\n"," {'start': 101.7730612244898,\n","  'text': ' Charlie runs back to his house and then calls the police'},\n"," {'start': 104.86131519274376,\n","  'text': ' and they come to the house and the dog attacked Charlie'},\n"," {'start': 108.32108843537415,\n","  'text': '  The officer gets into a car and Charlie and Emily are '},\n"," {'start': 111.80408163265307,\n","  'text': ' both taken to the hospital for observation and treatment'},\n"," {'start': 115.5657142857143,\n","  'text': ' They are then shown pictures of a girl and the old lady with the dog'},\n"," {'start': 118.72362811791383,\n","  'text': \" Charlie then realizes that the girl in the old lady's\"},\n"," {'start': 121.57968253968254,\n","  'text': ' locker is the girl in the pictures and tells him that'}]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GuEkNOktNyKy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634405290568,"user_tz":-180,"elapsed":293,"user":{"displayName":"Дарья Курганская","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10001247416734268166"}},"outputId":"251bdba0-f31d-4ff5-8351-ff5db2c07437"},"source":["print(len(data))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["33\n"]}]},{"cell_type":"code","metadata":{"id":"HMSE7Po-N0ls"},"source":["bigframe=[] \n","\n","for j in range(len(data)):\n"," \n","  init_frame = 1 # Это кадр, где Видео начнется\n","  last_frame = len(data) # номер последнего кадра. Также вызовет ошибку, если такого количества кадров не существует.\n"," \n","  min_fps = 1\n","  max_fps = 30\n"," \n","  total_frames = last_frame-init_frame\n","  \n","  if j != 0:\n","      length = data[j]['start'] - data[j - 1]['start'] - 1 #Tiempo deseado del vídeo en segundos\n","  else:\n","      length = data[j]['start'] - 1\n"," \n","  frames = []\n","  #tqdm.write('Generando video...')\n","  for i in range(len(data)):\n","    try: \n","        filename = f\"{path_for_video_series}/{i:03}.png\"\n","        frames.append(Image.open(filename))\n","    except FileNotFoundError as e:\n","        pass         \n","  print(frames)\n","  #fps = last_frame/10\n","  fps = np.clip(total_frames/length,min_fps,max_fps)\n","  name= f'video_{j:03}.mp4'\n"," \n","  from subprocess import Popen, PIPE\n","  p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', name], stdin=PIPE)\n","  for im in tqdm(frames):\n","    frames[j].save(p.stdin, 'PNG')\n","  p.stdin.close() \n","  p.wait()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JAuM0FJ9OCcK"},"source":["os.chdir(path_main)\n","\n","try:\n","    os.mkdir('output_video') # Создание папки и проверка её на наличие в директории\n","except OSError:\n","    pass\n","\n","path_to_videos1 = f'{path_for_morph}/videos1'\n","path_to_output_video = f'{path_main}/output_video'\n","\n","os.chdir(path_to_output_video)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YsJ-6S3xOD8I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634405352759,"user_tz":-180,"elapsed":268,"user":{"displayName":"Дарья Курганская","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10001247416734268166"}},"outputId":"1dea9b31-e043-43f8-81a5-74851cbe4ae2"},"source":["print(os.getcwd())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/aiijc/newFilm/pix1/output_video\n"]}]},{"cell_type":"code","metadata":{"id":"UYYepKTeOIRE"},"source":["import os\n","\n","clips=[] \n","\n","list_imgs = [x.split('/')[-1] for x in os.listdir(path_for_morph)]\n","\n","list_imgs_video = [x.split('/')[-1] for x in os.listdir(path_to_videos1)]\n","\n","from moviepy.editor import VideoFileClip, concatenate_videoclips\n","\n","for f1, f2 in zip(natsort.natsorted(list_imgs), natsort.natsorted(list_imgs_video)):\n","    name_1 = f'{path_for_morph}/{f1}'\n","    name_2 = f'{path_to_videos1}/{f2}'\n","    clips.append(VideoFileClip(name_2))\n","    clips.append(VideoFileClip(name_1))\n","\n","print(clips)\n","final_clip = concatenate_videoclips(clips, method=\"compose\")\n","final_clip.write_videofile(f\"{path_to_output_video}/{name_output_video}.mp4\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ShU1CsXAK0IB"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mWJqTDqqOQtw"},"source":["##Очистка папок (опционально)"]},{"cell_type":"code","metadata":{"id":"EQUG_Rs9ONlg"},"source":["import shutil\n","import os\n","\n","def delete_files(path1): # Функция удаления файлов и папок в папке с морфингом\n","    os.chdir(path1)\n","    folder = '.'\n","    for the_file in os.listdir(folder):\n","        file_path = os.path.join(folder, the_file)\n","        try:\n","            if os.path.isfile(file_path):\n","                os.unlink(file_path)\n","            elif os.path.isdir(file_path): shutil.rmtree(file_path)\n","        except Exception as e:\n","            pass\n","\n","delete_files(path_for_morph) # Вызов функции\n","delete_files(path_for_video_series)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TEeP_3wMS6i3"},"source":["#Обьединение со звуком"]},{"cell_type":"code","metadata":{"id":"UM8GPQ0F8wD6"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M5HOJa4zS6uw"},"source":["!pip install pydub\n","!pip install ffmpeg\n","from google.colab import files"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-uYwJ7_VS-Cl"},"source":["from pydub import AudioSegment\n","sound1 = AudioSegment.from_file(\"/content/voice.wav\", format=\"wav\")# путь до файла с голосом (надо закачать)\n","\n","sound2 = AudioSegment.from_file(\"/content/music.wav\", format=\"wav\") # путь до файла с музыкой (надо закачать)\n","sound2 = sound2 - 6 # на 6dB тише\n","overlay = sound1.overlay(sound2, position=0)\n","overlay.export('/content/audio.wav', format='wav') \n","!ffmpeg  -i /content/audio.wav -i /content/video.mp4 /content/DigiTale.mp4 #/content/video.mp4 = путь до файла с видео\n","files.download('/content/DigiTale.mp4')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZGbpdFyHTAP3"},"source":["#Фильм готов! Наслаждайтесь просмотром!"]}]}